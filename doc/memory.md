设计一个针对群聊场景的长期记忆系统是一个复杂且有趣的工程问题。群聊与单聊最大的区别在于**上下文的多样性**（多个人说话）、**信息的噪声**（闲聊多）以及**权限/隐私的边界**（A群的记忆不应随意泄露到B群）。

结合你使用的技术栈（Kotlin, Koin, Exposed）以及LLM特性，以下是一个不包含具体代码的架构设计方案。

---

### 一、 记忆维度的设计 (Memory Dimensions)

为了让LLM能够准确提取和检索，我们需要将记忆结构化。建议分为以下五个核心维度：

1.  **用户画像 (User Profile)**
    *   **定义**: 关于用户的静态或半静态属性。
    *   **内容**: 称呼、性别、职业、MBTI性格、语言风格（严肃/幽默）、在群内的角色（群主/潜水员/活跃分子）。
    *   **更新频率**: 低。

2.  **偏好设置 (Preferences)**
    *   **定义**: 用户明确要求的交互方式或配置。
    *   **内容**: “不要在晚上10点后@我”、“喜欢用Markdown格式回复”、“只关心Kotlin相关的技术话题”。
    *   **更新频率**: 中。

3.  **事实知识 (Facts/Knowledge)**
    *   **定义**: 群聊过程中产生的客观信息或达成的共识。
    *   **内容**: “群规是禁止发广告”、“项目A的上线时间是下周三”、“老王说他去过南极”。
    *   **更新频率**: 高。

4.  **待办与意图 (Todos & Intentions)**
    *   **定义**: 需要未来触发或持续关注的动态状态。
    *   **内容**: “提醒大家明天交周报”、“机器人稍后需要总结这段对话”、“用户A承诺下周分享技术”。
    *   **更新频率**: 高，且具有生命周期（创建->完成/过期）。

5.  **摘要与话题 (Summaries & Topics)**
    *   **定义**: 对长历史记录的压缩，用于对抗Token限制。
    *   **内容**: “上周主要讨论了Koin的依赖注入问题”、“昨天群里发生了关于缩进是用Tab还是空格的争论”。

---

### 二、 记忆的作用域 (Memory Scope)

这是群聊机器人的核心。你需要通过“Scope”字段来严格隔离数据：

1.  **全局域 (Global Scope)**
    *   **归属**: 绑定到 `UserID`。
    *   **逻辑**: 这是用户跨群通用的特征。例如用户的MBTI、编程语言偏好。无论他在哪个群，这些大概率不变。
    *   **隐私注意**: 只有非敏感信息才应放入全局域。

2.  **群组域 (Group Scope)**
    *   **归属**: 绑定到 `GroupID`。
    *   **逻辑**: 群公告、群内特定的话题、群成员之间的特定关系。这些信息离开这个群就没有意义。

3.  **成员-群组交叉域 (Member-Group Scope)**
    *   **归属**: 绑定到 `UserID` + `GroupID`。
    *   **逻辑**: 用户在该特定群里的表现或身份。例如，他在A群是“严厉的技术专家”，在B群是“摸鱼的闲聊者”。

---

### 三、 数据库表设计 (Schema Design via Exposed)

使用 Exposed 框架的思维设计表结构，建议采用**实体表 + 记忆碎片表**的模式。

#### 1. 基础实体表
*   **Users Table**: 存储用户基础ID、全局设置。
*   **Groups Table**: 存储群组ID、群名、群配置。

#### 2. 核心记忆表 (Memories Table)
这是最重要的一张表，存储所有的画像、偏好和事实。
*   **id**: 主键。
*   **scope_type**: 枚举值 (GLOBAL, GROUP, MEMBER_IN_GROUP)。
*   **user_id**: 关联用户 (可空，若为纯群组记忆则为空)。
*   **group_id**: 关联群组 (可空，若为全局记忆则为空)。
*   **category**: 维度标签 (PROFILE, PREFERENCE, FACT, SUMMARY)。
*   **content**: 记忆的具体文本内容（如 "用户喜欢吃辣"）。
*   **embedding**:  向量数据，用于语义搜索（Vector Search）。
*   **confidence**: 置信度 (0.0 - 1.0)，由LLM评估这条记忆的可靠性。
*   **last_updated**: 时间戳，用于遗忘机制（LRU）。

#### 3. 待办事项表 (Todos Table)
因为待办事项需要状态流转，建议独立建表。
*   **id**: 主键。
*   **group_id**: 关联群组。
*   **creator_id**: 创建者。
*   **assignee_id**: 执行者/被提醒人。
*   **description**: 任务描述。
*   **trigger_time**: 触发时间。
*   **status**: 状态 (PENDING, COMPLETED, CANCELLED)。

---

### 四、 LLM 交互与管理流程

如何让 LLM 读写这些记忆？不要让同一个 Prompt 既负责聊天又负责管理记忆，这会造成精神分裂。建议采用 **双流架构 (Dual-Stream Architecture)**。

#### 1. 聊天流 (Chat Flow) - "读取记忆"
当收到用户消息时：
1.  **检索 (Retrieval)**:
    *   根据 `user_id` 和 `group_id` 查询数据库。
    *   *策略*: 提取该用户的 Global 记忆 + 该群的 Group 记忆 + 该用户在该群的 Member-Group 记忆。
    *   *优化*: 如果记忆太多，先对用户输入做 Embedding，去数据库里做向量相似度搜索，只取Top-K相关的记忆。
2.  **Prompt 构建**:
    *   System Prompt: "你是一个群聊助手。以下是关于当前对话环境的已知信息：[注入查询到的记忆列表]..."
    *   User Input: 用户当前的问题。
3.  **生成回复**: 机器人基于记忆和上下文回答。

#### 2. 记忆流 (Memory Flow) - "更新记忆"
这是设计最关键的部分。**不要在回复用户的同时更新记忆，而是异步进行。**

*   **触发时机**:
    *   每隔 N 条消息（如 10 条）。
    *   或者当检测到对话结束/长停顿。
    *   或者当用户显式说“记住xxx”。

*   **Prompt 设计 (记忆提取器)**:
    *   **输入**: 最近的 N 条群聊记录。
    *   **Prompt 指令**:
        > "请分析以下对话记录，提取新的信息以更新长期记忆。
        > 关注以下维度：用户画像、偏好、事实、待办。
        > 输出格式应包含：操作类型（新增/修改/删除）、作用域（群/个人）、记忆类别、内容。
        >
        > 示例：
        > - 用户A说'我下周去休假' -> {Op: 新增, Scope: 群内, Type: 事实, Content: '用户A下周休假'}
        > - 用户B说'别叫我小王，叫我王哥' -> {Op: 修改, Scope: 群内, Type: 偏好, Content: '用户B希望被称呼为王哥'}"

*   **处理逻辑 (Kotlin/Exposed)**:
    1.  解析 LLM 返回的结构化数据 (JSON)。
    2.  **去重与冲突检查**:
        *   如果是“新增”，先查库里有没有相似的。
        *   如果是“修改”，找到旧记录更新 `content` 和 `last_updated`。
        *   如果是“删除”（例如用户说“我不再喜欢吃辣了”），标记或物理删除旧记忆。
    3.  写入数据库。

---

### 五、 记忆管理策略 (Memory Management)

这是一个非常先进且符合当前Agent发展趋势的设计思路。将记忆的增删改查（CRUD）完全交给LLM通过 **Tool Use (Function Calling)** 来决策，而不是依靠硬编码规则，可以让机器人具备“自我进化”和“遗忘”的能力。

要实现**“参考历史语义”**进行更新（例如：用户说“我不喜欢吃辣了”，LLM能找到旧记忆“用户喜欢吃辣”并将其修改），核心在于**RAG（检索增强）与 Tool Calling 的结合**。

以下是基于 Kotlin + Koin + Exposed + LLM Tool Use 的深度设计方案：

### 一、 核心架构逻辑：检索-比对-操作 (Retrieve-Compare-Act)

你不能把数据库里几万条记忆都丢给LLM让它去改。必须分三步走：

1.  **Recall (语义召回)**: 当用户发来新消息，先将消息向量化，从数据库中检索出 Top-K 最相似的**旧记忆**。
2.  **Reasoning (LLM决策)**: 将【新消息】+【相关的旧记忆（带ID）】一起喂给LLM。LLM 判断是该新增一条、修改查到的那条、还是删除那条。
3.  **Action (工具执行)**: LLM 调用 `add`, `update`, `delete` 工具，Exposed 执行数据库操作。

---

### 二、 数据库表设计 (Exposed Schema)

为了支持LLM精确修改，必须暴露 `id` 给 LLM。同时需要 `embedding` 字段支持语义搜索。

---

### 三、 LLM 工具定义 (Tool Definitions)

你需要定义三个核心工具给LLM。注意，工具的描述（Description）非常重要，它是 Prompt 的一部分。

#### 1. `add_memory`
*   **描述**: 当用户信息中包含全新的事实、偏好或画像，且**当前上下文中没有冲突的旧记忆**时使用。
*   **参数**:
    *   `content` (String): 记忆内容（必须是独立的陈述句）。
    *   `scope` (String): 属于个人、群还是成员。
    *   `tags` (List<String>): 维度标签（偏好/事实/画像）。

#### 2. `update_memory`
*   **描述**: 当用户信息**修正、补充或改变**了已存在的某条记忆时使用。**必须**参考提供的“Existing Memories”列表中的ID。
*   **参数**:
    *   `memory_id` (Long): **必须对应召回上下文中的真实ID**。
    *   `new_content` (String): 修改后的内容。
    *   `reason` (String): 为什么要改（比如“用户改变了主意”）。

#### 3. `delete_memory`
*   **描述**: 当现有记忆被证明是错误的，或者用户明确要求遗忘，或者信息已经完全过时（失效）时使用。
*   **参数**:
    *   `memory_id` (Long): 对应召回上下文中的ID。

---

### 四、 LLM 提示词与处理流程 (Prompt Engineering)

这是整个系统的灵魂。你需要构造一个专门的“Memory Agent” Prompt。

#### 1. 输入上下文准备 (Kotlin 侧逻辑)
假设用户说：“别叫我小王了，以后叫我王总，还有我下周不去爬山了。”

**Step 1: 向量搜索**
系统拿着这句话去数据库做 Cosine Similarity 搜索，找到了两条旧记忆：
*   Memory A (ID=101): "用户A的昵称是小王" (Score: 0.85)
*   Memory B (ID=102): "用户A计划下周去爬山" (Score: 0.91)

**Step 2: 构建 Prompt**
```text
System: 你是一个专业的群聊记忆管理员。你的任务是根据用户最新的对话，通过调用工具来维护长期记忆库。

【现有相关记忆 (Existing Memories)】
[ID: 101] 内容: 用户A的昵称是小王
[ID: 102] 内容: 用户A计划下周去爬山

【当前对话 (Current Dialogue)】
用户A: 别叫我小王了，以后叫我王总，还有我下周不去爬山了。

【指令】
1. 分析当前对话与现有记忆的关系。
2. 如果是新信息，调用 add_memory。
3. 如果与现有记忆冲突或属于状态更新，调用 update_memory（必须使用对应的ID）。
4. 如果是取消、无效化，调用 delete_memory（必须使用对应的ID）。
5. 即使是微小的语义变化（如改名），也应视为 Update。
```

#### 2. LLM 的输出 (Expected Output)

LLM 会理解语义并返回 Tool Calls（函数调用）：

*   **Tool Call 1**: `update_memory(memory_id=101, new_content="用户A希望被称为王总", reason="用户要求更改称呼")`
*   **Tool Call 2**: `delete_memory(memory_id=102)`  *(或者 update 成 "用户A取消了下周的爬山计划"，看你定义的策略)*

---
